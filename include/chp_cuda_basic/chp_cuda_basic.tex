\chapter{CUDA编程基础}
现代机器学习中大量使用GPU设备来节省算法的运行时间，Caffe的一个重要特性就是对GPU的支持。但是，基于GPU的编程又是一个庞大的学习任务，因此本章将对GPU编程做简要介绍，目的是能够理解Caffe代码中关于GPU的使用。

% Section X.1
\section{内存管理}
% Section X.1.1
\subsection{分配内存}\label{cuda/mem/alloc}
\subsubsection{cudaMalloc()}
\begin{cnfrmfunc}
   \item{\kai{原型}}\\
      ​cudaError\_t cudaMalloc ( void** devPtr, size\_t size )
   \item{\kai{参数}}\\
     devPtr - 指向分配内存的指针\\
     size - 要分配的内存的大小
   \item{\kai{返回值}}\\
     cudaSuccess, cudaErrorMemoryAllocation
\end{cnfrmfunc}
  对于GPU设备端（device）内存的分配，常用的函数有cudaMalloc(void** ptr, int size)，该函数返回一个cudaError\_t类型的值。该函数在GPU显存上分配size个字节的空间，并在保存于主机端（host）的ptr所指向的内存中写入一个device端的地址（注意ptr指向的内存只能存放指针变量），该地址指向显存。
\subsubsection{cudaMallocHost()}
\begin{cnfrmfunc}
   \item{\kai{原型}}\\
     cudaError\_t cudaMallocHost 	(void** ptr, size\_t size) 	
   \item{\kai{参数}}\\
     ptr - 指向分配内存的指针\\
     size - 要分配的内存的大小
   \item{\kai{返回值}}\\
     cudaSuccess, cudaErrorMemoryAllocation
\end{cnfrmfunc}     
然而在host端分配内存时，可以使用cudaMallocHost(void** ptr, int size)或者cuda函数，该函数与常用的malloc()函数的区别是分配的内存为页锁定内存（Pinned Memory）。由于GPU知道内存的物理地址，因此可以使用直接内存访问技术（Direct Memory Access）在host和device之间复制数据，无需CPU的参与，可以提高效率。然而由于分配的内存为页锁定，因此无法使用虚拟内存技术，有耗尽主机内存的风险。
% Section X.1.2
\subsection{内存初始化}\label{cuda/mem/init}
\subsubsection{cudaMemset()}
\begin{cnfrmfunc}
   \item{\kai{原型}}\\
     cudaError\_t cudaMemset ( void* devPtr, int  value, size\_t count )
   \item{\kai{参数}}\\
     devPtr - 要设置的设备内存首地址
     value - 要设置的整型值
     count - 要设置的字节数
   \item{\kai{返回值}}\\
     cudaSuccess, cudaErrorInvalidValue, cudaErrorInvalidDevicePointer
\end{cnfrmfunc}
初始化设备端内存，将设备端指定内存设置为统一数值。
\subsubsection{cudaMemcpy()}
\begin{cnfrmfunc}
   \item{\kai{原型}}\\
      ​cudaError\_t cudaMemcpy ( void* dst, const void* src, size\_t count, cudaMemcpyKind kind )
   \item{\kai{参数}}\\
     dst - 拷贝目的地址\\
     src - 拷贝源地址\\
     count - 拷贝字节数\\
     kind - 拷贝类型
   \item{\kai{返回值}}\\
     cudaSuccess, cudaErrorInvalidValue, cudaErrorInvalidDevicePointer, cudaErrorInvalidMemcpyDirection
\end{cnfrmfunc}
该函数实现主机与设备之间的内存拷贝功能，其中kind参数的可选类型为：
\begin{cntable}{kind参数类型}{tab:cuda/mem/init/kind}
  \begin{tabular}{|c|l|}
    \hline
    类型 & 功能 \\ \hline
    cudaMemcpyHostToHost & 主机端与主机端内存拷贝 \\ \hline
    cudaMemcpyHostToDevice & 住居端向设备端内存拷贝 \\ \hline
    cudaMemcpyDeviceToHost & 设备端向主机端内存拷贝 \\ \hline
    cudaMemcpyDeviceToDevice & 设备端与设备端内存拷贝 \\ \hline
    cudaMemcpyDefault & 使用统一虚拟地址空间 \\ \hline
  \end{tabular}
\end{cntable}
\subsubsection{cudaMemcpyAsync()}
\begin{cnfrmfunc}
   \item{\kai{原型}}\\
     ​cudaError\_t cudaMemcpyAsync ( void* dst, const void* src, size\_t count, cudaMemcpyKind kind, cudaStream\_t stream = 0 )
   \item{\kai{参数}}\\
     dst - 拷贝目的地址\\
     src - 拷贝源地址\\
     count - 拷贝字节数\\
     kind - 拷贝类型\\
     stream - CUDA流号
   \item{\kai{返回值}}\\
     cudaSuccess, cudaErrorInvalidValue, cudaErrorInvalidDevicePointer, cudaErrorInvalidMemcpyDirection
\end{cnfrmfunc}
该函数可以异步执行一个内存拷贝操作，所以当函数调用返回时无法保证拷贝操作已经完成。这里需要重点介绍的是该函数的最后一个参数，流。流是为了实现并行执行两个或多个不同任务（也称做并发执行）而引入的概念。CUDA中的流是一个GPU操作队列，被添加到流中的操作会按照指定的顺序被执行。对于一个支持设备重叠功能的GPU，硬件在处理内存复制和核函数执行时分别采用不同的引擎:内存复制引擎和核函数执行引擎，能够在执行一个核函数的同时执行内存的复制操作，因此可以使用多个流来实现这种计算与数据传输的重叠。通过stream参数可以将内存复制操作添加到指定流中。
% Section X.1.3
\subsection{内存释放}\label{cuda/mem/free}
\subsubsection{cudaFreeHost()}
\begin{cnfrmfunc}
   \item{\kai{原型}}\\
    cudaError\_t cudaFreeHost (void* ptr)
   \item{\kai{参数}}\\
     ptr 指向待释放内存的指针
   \item{\kai{返回值}}\\
     cudaSuccess, cudaErrorInitializationError
\end{cnfrmfunc}
释放由cudaMallocHost()或者cudaHostAlloc()函数分配的页锁定内存。
\subsubsection{cudaFree()}
\begin{cnfrmfunc}
   \item{\kai{原型}}\\
      ​cudaError\_t cudaFree ( void* devPtr )
   \item{\kai{参数}}\\
     devptr 指向待释放内存的指针
   \item{\kai{返回值}}\\
     cudaSuccess, cudaErrorInvalidDevicePointer, cudaErrorInitializationError
\end{cnfrmfunc}
释放由cudaMalloc()或cudaMallocPitch()分配的内存。
% Section 2
\section{错误管理}\label{cuda/err}
\subsubsection{cudaGetErrorString()}
\begin{cnfrmfunc}
\item{\kai{原型}}\\
const char* cudaGetErrorString (cudaError\_t error) 
\item{\kai{参数}}\\
error - CUDA函数返回错误代码\\
\item{\kai{返回值}}\\
const char*
\end{cnfrmfunc}
该函数将CUDA函数返回的错误代码转换为字符串信息。

% Section 3
\section{设备设置}\label{cuda/basic/device}
\subsubsection{cudaGetDevice()}
\begin{cnfrmfunc}
\item{\kai{原型}}\\
cudaError\_t cudaGetDevice ( int* device ) 
\item{\kai{参数}}\\
device - 存储正在运行的设备号\\
\item{\kai{返回值}}\\
cudaSuccess
\end{cnfrmfunc}
获得当前主机线程所执行设备代码所在的设备号。
\subsubsection{cudaSetDevice()}
\begin{cnfrmfunc}
\item{\kai{原型}}\\
cudaError\_t cudaSetDevice ( in device ) 
\item{\kai{参数}}\\
device - 特定设备号\\
\item{\kai{返回值}}\\
cudaSuccess, cudaErrorInvalidDevice, cudaErrorDeviceAlreadyInUse
\end{cnfrmfunc}
将特定设备号的设备指定为当前设备。

